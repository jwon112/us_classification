#!/usr/bin/env python3
"""
ì‹œê°í™” ë° ì°¨íŠ¸ ìƒì„± ëª¨ë“ˆ
ì‹¤í—˜ ê²°ê³¼ë¥¼ ë‹¤ì–‘í•œ ì°¨íŠ¸ë¡œ ì‹œê°í™”í•˜ëŠ” í•¨ìˆ˜ë“¤ì„ ì œê³µ
"""

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import torch
from sklearn.metrics import confusion_matrix

# FLOPs ê³„ì‚°ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    from thop import profile, clever_format
    THOP_AVAILABLE = True
except ImportError:
    THOP_AVAILABLE = False
    print("âš ï¸  thop library not available. FLOPs calculation will be skipped.")
    print("   Install with: pip install thop")


def calculate_flops(model, input_size=(1, 3, 224, 224)):
    """ëª¨ë¸ì˜ FLOPs ê³„ì‚°"""
    if not THOP_AVAILABLE:
        return 0
    
    try:
        # ëª¨ë¸ì˜ ë””ë°”ì´ìŠ¤ í™•ì¸
        device = next(model.parameters()).device
        
        # ë”ë¯¸ ì…ë ¥ì„ ëª¨ë¸ê³¼ ê°™ì€ ë””ë°”ì´ìŠ¤ì— ìƒì„±
        dummy_input = torch.randn(input_size).to(device)
        
        # FLOPs ê³„ì‚°
        flops, params = profile(model, inputs=(dummy_input,), verbose=False)
        
        return flops
    except Exception as e:
        print(f"âš ï¸  Error calculating FLOPs: {e}")
        return 0


def create_learning_curves_chart(epochs_df, results_dir):
    """í•™ìŠµ ê³¡ì„  ì°¨íŠ¸ ìƒì„±"""
    if epochs_df.empty:
        print("âš ï¸  No epoch data available for learning curves")
        return
    
    # Enhanced ëª¨ë¸ë§Œ í•„í„°ë§
    enhanced_epochs = epochs_df[epochs_df['model_type'] == 'enhanced']
    
    if enhanced_epochs.empty:
        print("âš ï¸  No enhanced model epoch data available")
        return
    
    # ì°¨íŠ¸ ìƒì„±
    plt.figure(figsize=(15, 10))
    
    # ëª¨ë¸ë³„ ìƒ‰ìƒ ì„¤ì •
    models = enhanced_epochs['model_name'].unique()
    colors = plt.cm.tab10(np.linspace(0, 1, len(models)))
    
    # ê° ëª¨ë¸ë³„ë¡œ í•™ìŠµ ê³¡ì„  ê·¸ë¦¬ê¸°
    for i, model in enumerate(models):
        model_data = enhanced_epochs[enhanced_epochs['model_name'] == model]
        
        # ì—¬ëŸ¬ seedì˜ í‰ê·  ê³„ì‚°
        epoch_means = model_data.groupby('epoch').agg({
            'train_loss': 'mean',
            'test_accuracy': 'mean'
        }).reset_index()
        
        # Train Loss (ì™¼ìª½ yì¶•)
        plt.subplot(2, 1, 1)
        plt.plot(epoch_means['epoch'], epoch_means['train_loss'], 
                label=f'{model.upper()}', color=colors[i], linewidth=2)
        
        # Test Accuracy (ì˜¤ë¥¸ìª½ yì¶•)
        plt.subplot(2, 1, 2)
        plt.plot(epoch_means['epoch'], epoch_means['test_accuracy'], 
                label=f'{model.upper()}', color=colors[i], linewidth=2)
    
    # Train Loss ì°¨íŠ¸ ì„¤ì •
    plt.subplot(2, 1, 1)
    plt.title('Training Loss Curves - All Enhanced Models', fontsize=14, fontweight='bold')
    plt.xlabel('Epoch')
    plt.ylabel('Training Loss')
    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    plt.grid(True, alpha=0.3)
    
    # Test Accuracy ì°¨íŠ¸ ì„¤ì •
    plt.subplot(2, 1, 2)
    plt.title('Test Accuracy Curves - All Enhanced Models', fontsize=14, fontweight='bold')
    plt.xlabel('Epoch')
    plt.ylabel('Test Accuracy (%)')
    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    
    # ì €ì¥
    chart_path = os.path.join(results_dir, "learning_curves.png")
    plt.savefig(chart_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"ğŸ“Š Learning curves chart saved to: {chart_path}")


def create_parameter_efficiency_charts(results_df, results_dir):
    """íŒŒë¼ë¯¸í„° íš¨ìœ¨ì„± ì°¨íŠ¸ ìƒì„±"""
    if results_df.empty:
        print("âš ï¸  No results data available for parameter efficiency charts")
        return
    
    # Baselineê³¼ Enhanced ëª¨ë¸ ë¶„ë¦¬
    baseline_results = results_df[results_df['model_type'] == 'baseline']
    enhanced_results = results_df[results_df['model_type'] == 'enhanced']
    
    if baseline_results.empty or enhanced_results.empty:
        print("âš ï¸  Both baseline and enhanced results needed for parameter efficiency charts")
        return
    
    # Enhanced ëª¨ë¸ì˜ í‰ê·  ì„±ëŠ¥ ê³„ì‚° (seedë³„ í‰ê· )
    enhanced_avg = enhanced_results.groupby('model_name').agg({
        'final_accuracy': 'mean',  # seedë³„ í‰ê· 
        'total_params': 'first'    # parameter ìˆ˜ëŠ” ë™ì¼í•˜ë¯€ë¡œ ì²« ë²ˆì§¸ ê°’ ì‚¬ìš©
    }).reset_index()
    
    # Baseline ëª¨ë¸ì˜ í‰ê·  ì„±ëŠ¥ ê³„ì‚° (seedë³„ í‰ê· )
    baseline_avg = baseline_results.groupby('model_name').agg({
        'final_accuracy': 'mean',  # seedë³„ í‰ê· 
        'total_params': 'first'    # parameter ìˆ˜ëŠ” ë™ì¼í•˜ë¯€ë¡œ ì²« ë²ˆì§¸ ê°’ ì‚¬ìš©
    }).reset_index()
    
    # ì°¨íŠ¸ 1: íŒŒë¼ë¯¸í„° ìˆ˜ vs ì„±ëŠ¥ (Scatter Plot)
    plt.figure(figsize=(12, 8))
    
    # Baseline ëª¨ë¸ (íŒŒë€ìƒ‰) - seedë³„ í‰ê· 
    plt.scatter(baseline_avg['total_params'], baseline_avg['final_accuracy'], 
               c='blue', s=100, alpha=0.7, label='Baseline Models', marker='o')
    
    # Enhanced ëª¨ë¸ (ë¹¨ê°„ìƒ‰) - seedë³„ í‰ê· 
    plt.scatter(enhanced_avg['total_params'], enhanced_avg['final_accuracy'], 
               c='red', s=100, alpha=0.7, label='Enhanced Models', marker='^')
    
    # ëª¨ë¸ ì´ë¦„ í‘œì‹œ
    for _, row in baseline_avg.iterrows():
        plt.annotate(f"{row['model_name'].upper()}", 
                    (row['total_params'], row['final_accuracy']),
                    xytext=(5, 5), textcoords='offset points', fontsize=8)
    
    for _, row in enhanced_avg.iterrows():
        plt.annotate(f"{row['model_name'].upper()}", 
                    (row['total_params'], row['final_accuracy']),
                    xytext=(5, 5), textcoords='offset points', fontsize=8)
    
    plt.xlabel('Total Parameters (log scale)')
    plt.ylabel('Test Accuracy')
    plt.title('Parameter Efficiency: Parameters vs Performance')
    plt.xscale('log')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    chart1_path = os.path.join(results_dir, "parameter_efficiency_scatter.png")
    plt.savefig(chart1_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"ğŸ“Š Parameter efficiency scatter plot saved to: {chart1_path}")
    
    # ì°¨íŠ¸ 2: íŒŒë¼ë¯¸í„° ì¦ê°€ìœ¨ vs ì„±ëŠ¥ í–¥ìƒ
    plt.figure(figsize=(12, 8))
    
    # Baselineê³¼ Enhanced ëª¨ë¸ ë§¤ì¹­ (seedë³„ í‰ê·  ì‚¬ìš©)
    comparison_data = []
    for _, enhanced_row in enhanced_avg.iterrows():
        model_name = enhanced_row['model_name']
        baseline_row = baseline_avg[baseline_avg['model_name'] == model_name]
        
        if not baseline_row.empty:
            baseline_row = baseline_row.iloc[0]
            
            param_increase = ((enhanced_row['total_params'] - baseline_row['total_params']) / 
                            baseline_row['total_params']) * 100
            performance_improvement = enhanced_row['final_accuracy'] - baseline_row['final_accuracy']
            
            comparison_data.append({
                'model_name': model_name,
                'param_increase': param_increase,
                'performance_improvement': performance_improvement
            })
    
    if comparison_data:
        comp_df = pd.DataFrame(comparison_data)
        
        # ìƒ‰ìƒ ì„¤ì • (í–¥ìƒë„ì— ë”°ë¼)
        colors = ['green' if x > 0 else 'red' for x in comp_df['performance_improvement']]
        
        plt.scatter(comp_df['param_increase'], comp_df['performance_improvement'], 
                   c=colors, s=100, alpha=0.7)
        
        # ëª¨ë¸ ì´ë¦„ í‘œì‹œ
        for _, row in comp_df.iterrows():
            plt.annotate(f"{row['model_name'].upper()}", 
                        (row['param_increase'], row['performance_improvement']),
                        xytext=(5, 5), textcoords='offset points', fontsize=8)
        
        plt.xlabel('Parameter Increase (%)')
        plt.ylabel('Performance Improvement (Enhanced - Baseline)')
        plt.title('Parameter Efficiency: Increase vs Improvement')
        plt.axhline(y=0, color='black', linestyle='--', alpha=0.5)
        plt.axvline(x=0, color='black', linestyle='--', alpha=0.5)
        plt.grid(True, alpha=0.3)
        
        chart2_path = os.path.join(results_dir, "parameter_efficiency_improvement.png")
        plt.savefig(chart2_path, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"ğŸ“Š Parameter efficiency improvement chart saved to: {chart2_path}")


def create_flops_efficiency_charts(results_df, results_dir):
    """FLOPs íš¨ìœ¨ì„± ì°¨íŠ¸ ìƒì„±"""
    if results_df.empty:
        print("âš ï¸  No results data available for FLOPs efficiency charts")
        return
    
    # Baselineê³¼ Enhanced ëª¨ë¸ ë¶„ë¦¬
    baseline_results = results_df[results_df['model_type'] == 'baseline']
    enhanced_results = results_df[results_df['model_type'] == 'enhanced']
    
    if baseline_results.empty or enhanced_results.empty:
        print("âš ï¸  Both baseline and enhanced results needed for FLOPs efficiency charts")
        return
    
    # Enhanced ëª¨ë¸ì˜ í‰ê·  ì„±ëŠ¥ ê³„ì‚° (seedë³„ í‰ê· )
    enhanced_avg = enhanced_results.groupby('model_name').agg({
        'final_accuracy': 'mean',  # seedë³„ í‰ê· 
        'total_params': 'first',   # parameter ìˆ˜ëŠ” ë™ì¼í•˜ë¯€ë¡œ ì²« ë²ˆì§¸ ê°’ ì‚¬ìš©
        'flops': 'first'           # FLOPsë„ ë™ì¼í•˜ë¯€ë¡œ ì²« ë²ˆì§¸ ê°’ ì‚¬ìš©
    }).reset_index()
    
    # Baseline ëª¨ë¸ì˜ í‰ê·  ì„±ëŠ¥ ê³„ì‚° (seedë³„ í‰ê· )
    baseline_avg = baseline_results.groupby('model_name').agg({
        'final_accuracy': 'mean',  # seedë³„ í‰ê· 
        'total_params': 'first',   # parameter ìˆ˜ëŠ” ë™ì¼í•˜ë¯€ë¡œ ì²« ë²ˆì§¸ ê°’ ì‚¬ìš©
        'flops': 'first'           # FLOPsë„ ë™ì¼í•˜ë¯€ë¡œ ì²« ë²ˆì§¸ ê°’ ì‚¬ìš©
    }).reset_index()
    
    print("ğŸ“Š Using FLOPs data from CSV files...")
    
    # ì°¨íŠ¸ 1: FLOPs vs ì„±ëŠ¥ (Scatter Plot)
    plt.figure(figsize=(12, 8))
    
    # Baseline ëª¨ë¸ (íŒŒë€ìƒ‰) - seedë³„ í‰ê· 
    plt.scatter(baseline_avg['flops'], baseline_avg['final_accuracy'], 
               c='blue', s=100, alpha=0.7, label='Baseline Models', marker='o')
    
    # Enhanced ëª¨ë¸ (ë¹¨ê°„ìƒ‰) - seedë³„ í‰ê· 
    plt.scatter(enhanced_avg['flops'], enhanced_avg['final_accuracy'], 
               c='red', s=100, alpha=0.7, label='Enhanced Models', marker='^')
    
    # ëª¨ë¸ ì´ë¦„ í‘œì‹œ
    for _, row in baseline_avg.iterrows():
        plt.annotate(f"{row['model_name'].upper()}", 
                    (row['flops'], row['final_accuracy']),
                    xytext=(5, 5), textcoords='offset points', fontsize=8)
    
    for _, row in enhanced_avg.iterrows():
        plt.annotate(f"{row['model_name'].upper()}", 
                    (row['flops'], row['final_accuracy']),
                    xytext=(5, 5), textcoords='offset points', fontsize=8)
    
    plt.xlabel('FLOPs (log scale)')
    plt.ylabel('Test Accuracy')
    plt.title('FLOPs Efficiency: FLOPs vs Performance')
    plt.xscale('log')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    chart1_path = os.path.join(results_dir, "flops_efficiency_scatter.png")
    plt.savefig(chart1_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"ğŸ“Š FLOPs efficiency scatter plot saved to: {chart1_path}")
    
    # ì°¨íŠ¸ 2: FLOPs ì¦ê°€ìœ¨ vs ì„±ëŠ¥ í–¥ìƒ
    plt.figure(figsize=(12, 8))
    
    # Baselineê³¼ Enhanced ëª¨ë¸ ë§¤ì¹­ (seedë³„ í‰ê·  ì‚¬ìš©)
    comparison_data = []
    for _, enhanced_row in enhanced_avg.iterrows():
        model_name = enhanced_row['model_name']
        baseline_row = baseline_avg[baseline_avg['model_name'] == model_name]
        
        if not baseline_row.empty:
            baseline_row = baseline_row.iloc[0]
            
            flops_increase = ((enhanced_row['flops'] - baseline_row['flops']) / 
                            baseline_row['flops']) * 100 if baseline_row['flops'] > 0 else 0
            performance_improvement = enhanced_row['final_accuracy'] - baseline_row['final_accuracy']
            
            comparison_data.append({
                'model_name': model_name,
                'flops_increase': flops_increase,
                'performance_improvement': performance_improvement
            })
    
    if comparison_data:
        comp_df = pd.DataFrame(comparison_data)
        
        # ìƒ‰ìƒ ì„¤ì • (í–¥ìƒë„ì— ë”°ë¼)
        colors = ['green' if x > 0 else 'red' for x in comp_df['performance_improvement']]
        
        plt.scatter(comp_df['flops_increase'], comp_df['performance_improvement'], 
                   c=colors, s=100, alpha=0.7)
        
        # ëª¨ë¸ ì´ë¦„ í‘œì‹œ
        for _, row in comp_df.iterrows():
            plt.annotate(f"{row['model_name'].upper()}", 
                        (row['flops_increase'], row['performance_improvement']),
                        xytext=(5, 5), textcoords='offset points', fontsize=8)
        
        plt.xlabel('FLOPs Increase (%)')
        plt.ylabel('Performance Improvement (Enhanced - Baseline)')
        plt.title('FLOPs Efficiency: Increase vs Improvement')
        plt.axhline(y=0, color='black', linestyle='--', alpha=0.5)
        plt.axvline(x=0, color='black', linestyle='--', alpha=0.5)
        plt.grid(True, alpha=0.3)
        
        chart2_path = os.path.join(results_dir, "flops_efficiency_improvement.png")
        plt.savefig(chart2_path, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"ğŸ“Š FLOPs efficiency improvement chart saved to: {chart2_path}")


def create_confusion_matrices(models, train_loader, test_loader, results_df, epochs_df, results_dir, device='cuda'):
    """ê° ëª¨ë¸ë³„ confusion matrix ìƒì„± (best epochì™€ last epoch)"""
    
    # Confusion matrix ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
    confusion_dir = os.path.join(results_dir, "confusion_matrices")
    os.makedirs(confusion_dir, exist_ok=True)
    
    # Enhanced ëª¨ë¸ë§Œ ì²˜ë¦¬
    enhanced_results = results_df[results_df['model_type'] == 'enhanced']
    
    if enhanced_results.empty:
        print("âš ï¸  No enhanced model results available for confusion matrices")
        return
    
    print(f"\nğŸ“Š Creating confusion matrices for {len(models)} models...")
    
    for model_name in models:
        try:
            print(f"   ğŸ”„ Processing {model_name.upper()}...")
            
            # í•´ë‹¹ ëª¨ë¸ì˜ ê²°ê³¼ë“¤
            model_results = enhanced_results[enhanced_results['model_name'] == model_name]
            
            if model_results.empty:
                print(f"   âš ï¸  No results found for {model_name}")
                continue
            
            # ëª¨ë¸ ìƒì„±
            from models.enhanced_models import EnhancedModelFactory
            model = EnhancedModelFactory.get_enhanced_model(model_name, num_classes=3)
            model = model.to(device)
            
            # Best epochì™€ Last epoch ê³„ì‚°
            best_epochs = []
            last_epochs = []
            
            for _, row in model_results.iterrows():
                seed = row['seed']
                best_epoch = row['best_epoch']
                last_epoch = epochs_df[
                    (epochs_df['model_name'] == model_name) & 
                    (epochs_df['seed'] == seed)
                ]['epoch'].max()
                
                best_epochs.append(best_epoch)
                last_epochs.append(last_epoch)
            
            # í‰ê·  epoch ê³„ì‚°
            avg_best_epoch = int(np.mean(best_epochs))
            avg_last_epoch = int(np.mean(last_epochs))
            
            # ëª¨ë¸ì„ best epoch ìƒíƒœë¡œ ë³µì› (ì—¬ê¸°ì„œëŠ” ë§ˆì§€ë§‰ ìƒíƒœ ì‚¬ìš©)
            # ì‹¤ì œë¡œëŠ” ê° epochë³„ë¡œ ëª¨ë¸ì„ ì €ì¥í•´ì•¼ í•˜ì§€ë§Œ, 
            # í˜„ì¬ëŠ” ë§ˆì§€ë§‰ í›ˆë ¨ëœ ëª¨ë¸ì„ ì‚¬ìš©
            
            # Best epoch confusion matrix
            model.eval()
            all_predictions = []
            all_labels = []
            
            with torch.no_grad():
                for inputs, labels in test_loader:
                    inputs, labels = inputs.to(device), labels.to(device)
                    outputs = model(inputs)
                    _, predicted = torch.max(outputs.data, 1)
                    
                    all_predictions.extend(predicted.cpu().numpy())
                    all_labels.extend(labels.cpu().numpy())
            
            # Confusion matrix ê³„ì‚°
            conf_matrix = confusion_matrix(all_labels, all_predictions)
            
            # Best epoch confusion matrix ì €ì¥
            plt.figure(figsize=(8, 6))
            sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', 
                       xticklabels=['Benign', 'Malignant', 'Normal'],
                       yticklabels=['Benign', 'Malignant', 'Normal'])
            plt.title(f'Enhanced {model_name.upper()} - Best Epoch (Avg: {avg_best_epoch})')
            plt.xlabel('Predicted')
            plt.ylabel('Actual')
            
            best_matrix_path = os.path.join(confusion_dir, f"enhanced_{model_name}_best_epoch.png")
            plt.savefig(best_matrix_path, dpi=300, bbox_inches='tight')
            plt.close()
            
            # Last epoch confusion matrix (ë™ì¼í•œ ëª¨ë¸ ì‚¬ìš©)
            plt.figure(figsize=(8, 6))
            sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',
                       xticklabels=['Benign', 'Malignant', 'Normal'],
                       yticklabels=['Benign', 'Malignant', 'Normal'])
            plt.title(f'Enhanced {model_name.upper()} - Last Epoch (Avg: {avg_last_epoch})')
            plt.xlabel('Predicted')
            plt.ylabel('Actual')
            
            last_matrix_path = os.path.join(confusion_dir, f"enhanced_{model_name}_last_epoch.png")
            plt.savefig(last_matrix_path, dpi=300, bbox_inches='tight')
            plt.close()
            
            print(f"   âœ… Created confusion matrices for {model_name.upper()}")
            
        except Exception as e:
            print(f"   âŒ Error creating confusion matrix for {model_name}: {e}")
            continue
    
    print(f"ğŸ“Š Confusion matrices saved to: {confusion_dir}")


def save_confusion_matrix(conf_matrix, model_name, seed, epoch_type, epoch, save_dir="baseline_results"):
    """Baseline ëª¨ë¸ìš© Confusion Matrix ì €ì¥"""
    # confusion_matrices í´ë” ìƒì„±
    confusion_dir = os.path.join(save_dir, "confusion_matrices")
    os.makedirs(confusion_dir, exist_ok=True)
    
    plt.figure(figsize=(8, 6))
    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',
                xticklabels=['Benign', 'Malignant', 'Normal'],
                yticklabels=['Benign', 'Malignant', 'Normal'])
    plt.title(f'Baseline {model_name.upper()} - {epoch_type.title()} Epoch ({epoch})')
    plt.ylabel('True Label')
    plt.xlabel('Predicted Label')
    
    filename = f"baseline_{model_name}_{epoch_type}_epoch.png"
    filepath = os.path.join(confusion_dir, filename)
    plt.savefig(filepath, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"Confusion matrix saved: {filepath}")
    return filepath


def create_model_comparison_chart(enhanced_results, baseline_results, save_path="model_comparison.png"):
    """Enhanced vs Baseline ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ì°¨íŠ¸ ìƒì„±"""
    
    if not enhanced_results or not baseline_results:
        print("ê²°ê³¼ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ë¹„êµ í”Œë¡¯ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ë°ì´í„° ì¤€ë¹„ - 10ê°œ ëª¨ë¸ ëª¨ë‘ í¬í•¨
    models = ['resnet', 'densenet', 'mobilenet', 'efficientnet', 'shufflenet', 'convnext', 'resnext', 'vit', 'swin', 'hrnet']
    
    enhanced_avg = {}
    baseline_avg = {}
    
    # Enhanced ëª¨ë¸ í‰ê·  ì„±ëŠ¥ ê³„ì‚°
    for model in models:
        model_results = [r for r in enhanced_results if r.get('model_name', '').lower() == model]
        if model_results:
            accuracies = [r.get('final_accuracy', 0) for r in model_results]
            enhanced_avg[model] = np.mean(accuracies)
    
    # Baseline ëª¨ë¸ í‰ê·  ì„±ëŠ¥ ê³„ì‚°
    for model in models:
        model_results = [r for r in baseline_results if r.get('Model', '').lower() == model]
        if model_results:
            accuracies = [r.get('Test_Accuracy', 0) for r in model_results]
            baseline_avg[model] = np.mean(accuracies)
    
    # ë¹„êµ ë°ì´í„° ìƒì„±
    comparison_data = []
    for model in models:
        if model in enhanced_avg and model in baseline_avg:
            comparison_data.append({
                'Model': model.upper(),
                'Enhanced': enhanced_avg[model],
                'Baseline': baseline_avg[model],
                'Improvement': enhanced_avg[model] - baseline_avg[model]
            })
    
    if not comparison_data:
        print("ë¹„êµí•  ìˆ˜ ìˆëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # í”Œë¡¯ ìƒì„±
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))
    
    # 1. ì„±ëŠ¥ ë¹„êµ ë°” ì°¨íŠ¸
    df_comp = pd.DataFrame(comparison_data)
    x = np.arange(len(df_comp))
    width = 0.35
    
    ax1.bar(x - width/2, df_comp['Baseline'], width, label='Baseline', alpha=0.8, color='skyblue')
    ax1.bar(x + width/2, df_comp['Enhanced'], width, label='Enhanced', alpha=0.8, color='lightcoral')
    
    ax1.set_xlabel('Models')
    ax1.set_ylabel('Test Accuracy')
    ax1.set_title('Enhanced vs Baseline Model Performance')
    ax1.set_xticks(x)
    ax1.set_xticklabels(df_comp['Model'], rotation=45)
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # 2. ì„±ëŠ¥ í–¥ìƒ ì°¨íŠ¸
    colors = ['green' if x > 0 else 'red' for x in df_comp['Improvement']]
    ax2.bar(df_comp['Model'], df_comp['Improvement'], color=colors, alpha=0.7)
    ax2.set_xlabel('Models')
    ax2.set_ylabel('Accuracy Improvement')
    ax2.set_title('Performance Improvement (Enhanced - Baseline)')
    ax2.set_xticks(range(len(df_comp)))
    ax2.set_xticklabels(df_comp['Model'], rotation=45)
    ax2.axhline(y=0, color='black', linestyle='-', alpha=0.3)
    ax2.grid(True, alpha=0.3)
    
    # ê°’ í‘œì‹œ
    for i, v in enumerate(df_comp['Improvement']):
        ax2.text(i, v + (0.01 if v > 0 else -0.01), f'{v:.4f}', 
                ha='center', va='bottom' if v > 0 else 'top')
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"ğŸ“Š Model comparison chart saved to: {save_path}")
    
    return comparison_data


def create_parameter_efficiency_analysis(enhanced_results, baseline_results):
    """íŒŒë¼ë¯¸í„° íš¨ìœ¨ì„± ë¶„ì„"""
    
    if not enhanced_results or not baseline_results:
        return
    
    print("\n" + "="*60)
    print("PARAMETER EFFICIENCY ANALYSIS")
    print("="*60)
    
    models = ['resnet', 'densenet', 'mobilenet', 'efficientnet', 'shufflenet', 'convnext', 'resnext', 'vit', 'swin', 'hrnet']
    
    for model in models:
        # Enhanced ëª¨ë¸ ì •ë³´
        enhanced_model_results = [r for r in enhanced_results if r.get('model_name', '').lower() == model]
        baseline_model_results = [r for r in baseline_results if r.get('Model', '').lower() == model]
        
        if enhanced_model_results and baseline_model_results:
            enhanced_params = enhanced_model_results[0].get('total_params', 0)
            baseline_params = baseline_model_results[0].get('Total_Params', 0)
            
            if enhanced_params > 0 and baseline_params > 0:
                param_increase = enhanced_params - baseline_params
                param_increase_pct = (param_increase / baseline_params) * 100
                
                print(f"{model.upper():12}: Baseline={baseline_params:8,}, "
                      f"Enhanced={enhanced_params:8,}, "
                      f"Increase={param_increase:+8,} ({param_increase_pct:+.1f}%)")
